"""
07a - Create AI Foundry Agent with SQL + AI Search Tools
Creates an AI Foundry agent that can query both structured data (SQL) and unstructured data (AI Search).

Usage:
    python 07a_create_foundry_agent.py

Prerequisites:
    - Run 01_generate_sample_data.py (creates data and ontology_config.json)
    - Run 02_setup_fabric.py (creates Lakehouse and Ontology)
    - Run 03_load_fabric_data.py (loads data to tables)
    - Run 04_generate_prompt.py (creates schema_prompt.txt)
    - Run 06_upload_to_search.py (uploads PDFs to AI Search)

The agent has two function tools:
    1. execute_sql - Query structured data in Fabric Lakehouse
    2. search_documents - Search unstructured PDF documents in AI Search
"""

import os
import sys
import json

# Get script directory for relative paths
script_dir = os.path.dirname(os.path.abspath(__file__))

# Load environment from azd + project .env
from load_env import load_all_env
load_all_env()

from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient
from azure.ai.projects.models import PromptAgentDefinition, FunctionTool

# ============================================================================
# Configuration
# ============================================================================

# Azure services - from azd environment
ENDPOINT = os.getenv("AZURE_AI_PROJECT_ENDPOINT")
MODEL = os.getenv("AZURE_CHAT_MODEL") or os.getenv("MODEL_DEPLOYMENT", "gpt-4o")
SEARCH_ENDPOINT = os.getenv("AZURE_AI_SEARCH_ENDPOINT")

# Project settings - from .env
DATA_FOLDER = os.getenv("DATA_FOLDER")

if not ENDPOINT:
    print("ERROR: AZURE_AI_PROJECT_ENDPOINT not set")
    print("       Run 'azd up' to deploy Azure resources")
    sys.exit(1)

if not DATA_FOLDER:
    print("ERROR: DATA_FOLDER not set in .env")
    print("       Run 01_generate_sample_data.py first")
    sys.exit(1)

if not SEARCH_ENDPOINT:
    print("ERROR: AZURE_AI_SEARCH_ENDPOINT not set")
    print("       Run 'azd up' to deploy Azure resources")
    sys.exit(1)

data_dir = os.path.abspath(DATA_FOLDER)

# Set up paths for new folder structure
config_dir = os.path.join(data_dir, "config")
if not os.path.exists(config_dir):
    config_dir = data_dir  # Fallback to old structure

# ============================================================================
# Load Ontology Config and Schema Prompt
# ============================================================================

# Load ontology config for scenario info
config_path = os.path.join(config_dir, "ontology_config.json")
if not os.path.exists(config_path):
    print(f"ERROR: ontology_config.json not found")
    print("       Run 01_generate_sample_data.py first")
    sys.exit(1)

with open(config_path) as f:
    ontology_config = json.load(f)

scenario = ontology_config.get("scenario", "retail")
scenario_name = ontology_config.get("name", "Business Data")
scenario_desc = ontology_config.get("description", "")
tables = list(ontology_config.get("tables", {}).keys())

# Load schema prompt (generated by 04_generate_prompt.py)
prompt_path = os.path.join(config_dir, "schema_prompt.txt")
if os.path.exists(prompt_path):
    with open(prompt_path) as f:
        schema_prompt = f.read()
else:
    schema_prompt = ""
    print("WARNING: schema_prompt.txt not found - run 04_generate_prompt.py first")

# Load Fabric IDs
fabric_ids_path = os.path.join(config_dir, "fabric_ids.json")
if not os.path.exists(fabric_ids_path):
    print(f"ERROR: fabric_ids.json not found")
    print("       Run 02_setup_fabric.py first")
    sys.exit(1)

with open(fabric_ids_path) as f:
    fabric_ids = json.load(f)

# Load Search IDs
search_ids_path = os.path.join(config_dir, "search_ids.json")
if os.path.exists(search_ids_path):
    with open(search_ids_path) as f:
        search_ids = json.load(f)
    INDEX_NAME = search_ids.get("index_name", f"{fabric_ids.get('solution_name', 'demo')}-documents")
else:
    INDEX_NAME = f"{fabric_ids.get('solution_name', 'demo')}-documents"
    print(f"WARNING: search_ids.json not found - using default index: {INDEX_NAME}")

WORKSPACE_ID = fabric_ids.get("workspace_id")
LAKEHOUSE_NAME = fabric_ids.get("lakehouse_name")
SOLUTION_NAME = fabric_ids.get("solution_name", "demo")
# Agent names: alphanumeric and hyphens only, must start/end with alphanumeric
AGENT_NAME = f"{SOLUTION_NAME}-multi-tool-agent"

print(f"\n{'='*60}")
print("Creating AI Foundry Agent with SQL + AI Search Tools")
print(f"{'='*60}")
print(f"Endpoint: {ENDPOINT}")
print(f"Model: {MODEL}")
print(f"Scenario: {scenario_name}")
print(f"Tables: {', '.join(tables)}")
print(f"Lakehouse: {LAKEHOUSE_NAME}")
print(f"Search Index: {INDEX_NAME}")

# ============================================================================
# Build Agent Instructions
# ============================================================================

def build_agent_instructions(config, schema_text):
    """Build optimized agent instructions for multi-tool scenario"""
    scenario_name = config.get("name", "Business Data")
    scenario_desc = config.get("description", "")
    tables_config = config.get("tables", {})
    relationships = config.get("relationships", [])
    
    # Build table descriptions
    table_names = list(tables_config.keys())
    
    # Build relationship descriptions for JOINs
    join_hints = []
    for rel in relationships:
        from_table = rel.get("from")
        to_table = rel.get("to")
        from_key = rel.get("fromKey")
        to_key = rel.get("toKey")
        join_hints.append(f"{from_table}.{from_key} = {to_table}.{to_key}")
    
    instructions = f"""You are a helpful data analyst assistant that answers questions about {scenario_name}.

{scenario_desc}

You have access to TWO tools:

## Tool 1: execute_sql
Use this for STRUCTURED DATA queries - numbers, counts, aggregations, specific records.
- Query the Fabric Lakehouse SQL endpoint
- Use T-SQL syntax
- Available tables: {', '.join(table_names)}
{schema_text}

## Tool 2: search_documents  
Use this for UNSTRUCTURED DATA queries - policies, guidelines, procedures, descriptions.
- Search PDF documents indexed in AI Search
- Good for: "What is the return policy?", "How does shipping work?", "What are the loyalty benefits?"
- Returns relevant text passages from documents

## Decision Guide:
- Numbers/counts/aggregations → execute_sql
- "How many...", "Total...", "Average...", "List all..." → execute_sql  
- Policies/procedures/guidelines → search_documents
- "What is the policy for...", "How do I...", "Explain..." → search_documents
- Complex questions may need BOTH tools - use them sequentially

## SQL Guidelines:
- Use T-SQL syntax compatible with Fabric Lakehouse
- Do NOT use schema prefixes (no dbo.) - just use table names directly
- Use proper aggregation functions: COUNT, SUM, AVG, MIN, MAX
- Always use GROUP BY when using aggregation with non-aggregated columns
- For JOINs use: {'; '.join(join_hints) if join_hints else 'check schema for foreign keys'}
- Use TOP N instead of LIMIT for row limiting

## Response Format:
1. Determine which tool(s) to use
2. Execute the appropriate tool(s)
3. Combine and summarize the results clearly

Be concise and accurate. If a query fails, explain the issue and try a different approach."""

    return instructions

instructions = build_agent_instructions(ontology_config, schema_prompt)
print(f"\nBuilt instructions ({len(instructions)} chars)")

# ============================================================================
# Tool Definitions
# ============================================================================

# SQL Execution Tool
execute_sql_tool = FunctionTool(
    name="execute_sql",
    description=f"Execute a SQL query against the Fabric Lakehouse to query structured data. Use for numbers, counts, aggregations, and specific records. Available tables: {', '.join(tables)}. Use T-SQL syntax.",
    parameters={
        "type": "object",
        "properties": {
            "sql_query": {
                "type": "string",
                "description": f"The T-SQL query to execute. Use table names: {', '.join(tables)}. Do not use schema prefixes."
            }
        },
        "required": ["sql_query"],
        "additionalProperties": False
    },
    strict=True
)

# AI Search Tool
search_documents_tool = FunctionTool(
    name="search_documents",
    description="Search PDF documents in Azure AI Search for policies, guidelines, procedures, and other unstructured information. Use for questions about 'how to', policies, procedures, guidelines, or explanatory content.",
    parameters={
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "The search query to find relevant documents. Use natural language - the search supports semantic understanding."
            }
        },
        "required": ["query"],
        "additionalProperties": False
    },
    strict=True
)

# ============================================================================
# Create the Agent
# ============================================================================

print("\nInitializing AI Project Client...")
credential = DefaultAzureCredential()

try:
    project_client = AIProjectClient(
        endpoint=ENDPOINT,
        credential=credential
    )
    print("[OK] AI Project Client initialized")
except Exception as e:
    print(f"[FAIL] Failed to initialize client: {e}")
    sys.exit(1)

try:
    with project_client:
        # Delete existing agent if it exists
        print(f"\nChecking if agent '{AGENT_NAME}' already exists...")
        try:
            existing_agent = project_client.agents.get(AGENT_NAME)
            if existing_agent:
                print(f"  Found existing agent, deleting...")
                project_client.agents.delete(AGENT_NAME)
                print(f"[OK] Deleted existing agent")
        except Exception:
            print(f"  No existing agent found")

        # Create agent definition with both tools
        print("\nCreating agent with SQL + AI Search tools...")
        agent_definition = PromptAgentDefinition(
            model=MODEL,
            instructions=instructions,
            tools=[execute_sql_tool, search_documents_tool]
        )
        
        agent = project_client.agents.create(
            name=AGENT_NAME,
            definition=agent_definition
        )
        
        print(f"\n[OK] Agent created successfully!")
        print(f"  Agent ID: {agent.id}")
        print(f"  Agent Name: {agent.name}")
        
except Exception as e:
    print(f"\n[FAIL] Failed to create agent: {e}")
    sys.exit(1)

# ============================================================================
# Save Agent Configuration
# ============================================================================

agent_ids_path = os.path.join(config_dir, "agent_ids.json")
agent_ids = {}
if os.path.exists(agent_ids_path):
    with open(agent_ids_path) as f:
        agent_ids = json.load(f)

agent_ids["multi_tool_agent_id"] = agent.id
agent_ids["multi_tool_agent_name"] = agent.name
agent_ids["endpoint"] = ENDPOINT
agent_ids["workspace_id"] = WORKSPACE_ID
agent_ids["lakehouse_name"] = LAKEHOUSE_NAME
agent_ids["search_index"] = INDEX_NAME

with open(agent_ids_path, "w") as f:
    json.dump(agent_ids, f, indent=2)

print(f"\n[OK] Agent config saved to: {agent_ids_path}")

# Update .env with FOUNDRY_AGENT_ID
env_path = os.path.join(script_dir, "..", ".env")
if os.path.exists(env_path):
    with open(env_path, "r") as f:
        env_content = f.read()
    
    lines = env_content.split("\n")
    updated = False
    for i, line in enumerate(lines):
        if line.startswith("FOUNDRY_AGENT_ID="):
            lines[i] = f"FOUNDRY_AGENT_ID={agent.id}"
            updated = True
            break
    
    if updated:
        with open(env_path, "w") as f:
            f.write("\n".join(lines))
        print(f"[OK] Updated .env with FOUNDRY_AGENT_ID={agent.id}")

# ============================================================================
# Summary
# ============================================================================

print(f"""
{'='*60}
Multi-Tool AI Foundry Agent Created Successfully!
{'='*60}

Agent ID: {agent.id}
Agent Name: {agent.name}
Model: {MODEL}
Scenario: {scenario_name}

Tools:
  1. execute_sql - Query structured data (Fabric Lakehouse)
  2. search_documents - Search unstructured data (AI Search)

Sample questions that REQUIRE both tools to answer:
  - "What's the total value of orders that qualify for free shipping based on our policy?"
  - "How many orders meet the minimum for loyalty rewards eligibility?"
  - "What revenue comes from categories with extended return windows per our policy?"

Next step:
  python scripts/08a_test_multi_tool_agent.py
""")


